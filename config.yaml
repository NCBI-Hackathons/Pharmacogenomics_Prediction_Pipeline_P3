# Top-level data dir
prefix: example_data

# List of feature sets to use while training. Anything selected here must be
# configured below.
features_to_use: [go, normed_counts, zscores, msigdb, cpdb, exome_variants, cnv]

# The value of "programs" should point to a YAML-formatted file that specifies
# preludes and paths to each program used throughout the pipeline.
#
# This mechanism allows us to support different systems where executables may
# not be on the default path. Furthermore, if a GNU Module needs to be loaded,
# it is done in the prelude. For example, on the cluster imagine we have to
# first load the module for bedtools before calling it, but once the module is
# loaded it is available on the path. In this case, the programs config file
# would have an entry like this:
#
# bedtools:
#   prelude: "module load bedtools"
#   path: "bedtools"
#
# If it's already on the default path, `prelude` can be empty. You can be as
# specific as you need to in the `path` entry.
#
# In any Snakemake rule using bedtools, use the following placeholders to fill
# in the configured prelude and path as follows:
#
# {programs.bedtools.prelude}
# {programs.bedtools.path} intersect -a a.bed -b b.bed
programs: programs.yaml

# Each set of features:
#   - has a unique name that can be used in the "features_to_use" list
#
#   - has one or more output files, which must be of the general format:
#       - rows = features
#       - columns = samples
#
#   - has a snakefile responsible for creating the output file.
#       - paths in these snakefiles should be relative to the runall.snakefile
#         since they are included verbatim.
#       - interdependencies between feature snakefiles can be handled by using
#         the snakemake directive "include:"
features:
    cnv:
        snakefile: features/cnv.snakefile
        output:
            clusters: "{prefix}/cleaned/cnv/cluster_scores.tab"
            max_gene: "{prefix}/cleaned/cnv/cnv_gene_max_scores.tab"
            longest_gene: "{prefix}/cleaned/cnv/cnv_gene_longest_overlap_scores.tab"

    exome_variants:
        snakefile: features/variants.snakefile
        output:
            by_gene: "{prefix}/cleaned/exome_variants/exome_variants_by_gene.tab"

    msigdb:
        snakefile: features/msigdb.snakefile
        output:
            zscores: "{prefix}/cleaned/msigdb/msigdb_zscores.csv"
            variants: "{prefix}/cleaned/msigdb/msigdb_variants.csv"
    go:
        snakefile: features/gene_ontology.snakefile
        output:
            zscores: "{prefix}/cleaned/go/go_zscores.csv"
            variants: "{prefix}/cleaned/go/go_variants.csv"

    cpdb:
        snakefile: features/cpdb.snakefile
        output:
            zscores: "{prefix}/cleaned/consensus_pathway/cpdb_zscores.csv"
            variants: "{prefix}/cleaned/consensus_pathway/cpdb_variants.csv"

    normed_counts:
        snakefile: features/normed_counts.snakefile
        output:
            normed_counts: "{prefix}/cleaned/rnaseq_expression/counts_matrix_normalized.csv"

    zscores:
        snakefile: features/zscores.snakefile
        output:
            zscores: "{prefix}/cleaned/rnaseq_expression/zscores.csv"
            #zscore_estimates: "{prefix}/cleaned/rnaseq_expression/zscore_estimates.csv"

run_info:
    # Each run defines a unique comination of feature filtering, response data,
    # and learning parameters.

    run_1:

        # The `run1` function, found in the Python module `filterfuncs.py`,
        # will be called on each feature set in this run.
        feature_filter: "filterfuncs.run1"

        # One model will be trained for each reponse listed the `response_list`
        # file.
        response_list: "SIDs.txt"

        # Specify the samples to use. This file can be used to globally filter
        # out a particular sample for this run
        sample_list: "celllines.txt"

        # The "process_response" rule creates several output files for each
        # sample. The `response_template` specifies which file to use, and must
        # include a {sample} placeholder in the filename. `response_column`
        # specifies which column in that file to use for the response data.
        response_template: "{prefix}/processed/drug_response/{sample}_drugResponse.tab"
        response_column: "DATA0"

        # R script defining the "SL.library" to use for SuperLearner.
        SL_library_file: "tools/default_SL_library.R"
